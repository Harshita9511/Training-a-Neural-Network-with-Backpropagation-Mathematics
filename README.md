# Training a Neural Network with Backpropagation - Mathematics

<img src="/backpropagation.gif" width="1000" height="300" />
<div align="justify">

Backpropagation is a widely used algorithm in training feedforward neural networks for supervised learning. It computes the gradient of the loss function with respect to the different weights and bias by using the chain rule of differential calculus. These gradients are used to update the weights and bias. Since these gradients are learned in the backward direction, starting from the output node, this learning process is referred to as the backward propagation.<br>
This work attempts to explain how backpropagation works with the help of a concrete example and the blog post can be accessed by the given link - https://inblog.in/Part-2-Training-a-Neural-Network-with-Backpropagation-Mathematics-bdyEJx6bKU
</div>
